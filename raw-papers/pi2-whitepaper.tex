\documentclass{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref,cleveref}
\usepackage{tikz}
\usepackage{url}
\usepackage{xspace}


\newcommand{\code}[1]{\texttt{#1}}

\title{The Pi Squared ($\pi^2$) White Paper\\\Large Version 1.0}
\author{Pi Squared Inc.}
\date{February 2025}


\newcommand{\K}{\ensuremath{\mathbb{K}}\xspace}
\newcommand{\ld}{.\,}
\newcommand{\To}{\Rightarrow}
\newcommand{\init}{{\textit{init}}}
\newcommand{\final}{{\textit{final}}}
\newcommand{\KL}{LLVM-\K}
\newcommand{\ulm}{ULM}

\begin{document}
\maketitle

\abstract{
Pi Squared is set to massively disrupt the state-of-the-art and revolutionize Web3 by making the following features mainstream:
\begin{enumerate}
    \item {\textbf{Universality}:} Programs will be written in any programming languages, virtual machines (VMs), or instruction sets that applications choose.  Developers will no longer need to learn poorly designed languages only because that's the only way to write Web3 programs.  Program executions will be proved using any mathematical or cryptographic proof systems that the applications choose.  They will no longer need to take the risk of introducing bugs and increasing complexity by translating their code to restricted or obscure low-level languages, only because that is the only way to use existing zero-knowledge virtual machines (zkVMs) to prove their executions.  And finally, applications will choose which consensus fits them best: can be a total-order consensus, like in blockchains, rollups, appchains, etc., or a partial-order or even no order at all, like in voting, auction, or trading applications.  Applications will no longer need to squeeze their transactions in a global total order across all the applications in the universe, through a narrow pipe.
    \item {\textbf{Correctness}:} All the above will be \textit{correct by construction}.  Specifically, once a formal semantics of the language is provided\footnote{A formal semantics is a fundamental requirement in any setting where correctness matters.  Without a formal semantics we cannot even define what correctness means.}, all the execution and proving tools for that language are automatically derived and everything they do is provably and verifiably correct at no additional effort.  No formal verification of translators, compilers, interpreters,
    VMs, zkVMs, etc., will be required.  
    \item {\textbf{Performance}:} No, universality and correctness should not and will not come at the cost of performance.  Quite the contrary.  After more than fifty (50) years of sustained research and engineering, the formal semantics domain has reached a level of maturity and tooling that allows semantics-based execution to match and even outperform the traditional, ad-hoc manual implementations of compilers and interpreters/VMs.  
    The future is even brighter because formal semantics enables a series of optimizations that are simply not possible using traditional approaches, such as symbolic semantic summarization of basic blocks or using formal verification to non-asymptotically compress or even eliminate computation.
\end{enumerate}

This paper gives a high-level overview of Pi Squared and of its three major technical components, namely the K Framework, Proof of Proof, and the Universality Stack, focusing on {\em what} and {\em why}.  For {\em how}, the reader is encouraged to dive deeper into our three component-specific white papers as well as our research and peer-reviewed publications at 
\href{https://pi2.network/papers}{\texttt{pi2.network/papers}}.
}

\renewcommand{\contentsname}{Table of Contents}
\setcounter{tocdepth}{3}
\tableofcontents

\newpage

\section{Introduction}

Web3 infrastructure yearns for more universality and trustworthiness.
Current solutions are constrained by technological limitations 
such as specificity to particular computing models (e.g., programming languages, virtual machines, or instruction sets), reliance on error-prone translations among languages, lack of provable correctness, and slow performance.
In this paper, we present Pi Squared and its three core technological innovations
that address the above technological limitations:
\begin{itemize}
\item \textbf{\K Framework}: A universal programming language framework that enables fast and correct-by-construction computation for programs written in any programming language or virtual machine.
\item \textbf{Proof of Proof}: A universal verifiable computing framework designed to generate complete, rigorous, and machine-checkable proofs for the execution of programs in any programming language.
\item \textbf{Universality Stack}: The Pi Squared universality stack that
consists of the following three components: the universal settlement layer (USL),
the universal language machine (ULM), and the universal consensus protocol (UCP). 
\end{itemize}

\subsection{\K Framework}

Traditional programming and computing space are plagued by (programming) 
language barriers. 
On the one hand, we have a large and increasing number of programming languages as new
domains, new applications, and new demands arise,
such as the Ethereum virtual machine's bytecode language for the Ethereum network. 
On the other hand, the development of the tool support of programming languages
is still managed the same way as half a century ago: 
People develop specific tools 
(compilers, interpreters, formal verifiers, and ZK provers) 
for specific programming languages, 
virtual machines, and/or architecture set instructions. 

Language-specific tools lead to language-specific tech stacks and infrastructure,
which lead to language-specific ecosystems,
and eventually, result in a huge programming language barrier
in the current programming and computing space. 
Web2 programmers must first learn how to write code in Solidity.
Game developers must first translate their application to a specific zkVM implementing hundreds of thousands or lines of code that is blindly trusted, for which compilers may not even exist. 
Otherwise, they are effectively excluded by the emerging Web3 community. 
Language barriers make learning, development, deployment, and maintenance
more expensive,
increasing fragmentation and decreasing interoperability. 

The \href{https://kframework.org}{\K framework} breaks language barriers in the programming space using 
\emph{formal semantics}. 
\K allows anyone to define the formal semantics
of any programming language, virtual machine, or architecture set in it.
Furthermore, from the formal semantics, \K automatically generates all the language tools in a correct-by-construction manner. 
This way, \K fundamentally changes how the tool support of programming languages
is developed. 
Instead of working on all the language-tool combinations, 
\K separates language design and tool implementation.

\K was invented at University of Illinois at Urbana-Champaign in 2003
by Prof. Grigore Rosu, the founder of Pi Squared,
and has been continuously improved since then.
As of today, 
\K has been successfully applied to define the formal semantics of 
C~\cite{c-semantics}, 
Java~\cite{java-semantics}, 
JavaScript~\cite{kjs}, 
Python~\cite{python-semantics}, 
Rust~\cite{krust-shanghai,krust-singapore},
EVM~\cite{kevm}, 
WASM~\cite{kwasm}, 
x86-64~\cite{DPK+19}, 
and more.
\K constitutes the infrastructural foundation of a unique approach 
to verifiable computing,
initiated and developed at Pi Squared, called Proof of Proof.



\subsection{Proof of Proof}

Verifiable computing is poised to become the cornerstone of trust and correctness in decentralized Web3 infrastructure. 
Pi Squared's Proof of Proof is an approach to verifiable computing that puts
special emphasis on \emph{universality} and \emph{correct-by-construction}, 
which we term ``Verifiable Computing 2.0.''
Universality means that Proof of Proof is a framework that works for all programming
languages, virtual machines, and instruction set architectures. 
Correct-by-construction means that Proof of Proof directly uses the mathematical models
of the systems-being-verified to construct the correctness certificates, so there is
no modeling gap between the systems and their certificates. 
Both universality and correct-by-construction are a natural consequence of the semantics-based approach of Proof of Proof,
which is directly built on top of the \K framework
and the formal semantics of various programming languages and virtual machines in it. 

Proof of Proof stands for zero-knowledge (ZK) proofs of math proofs. 
As its name suggests, Proof of Proof involves two types of proofs:
math proofs and ZK proofs. 
Given a program in a programming language,
we first generate a math proof 
that is fast to generate, easy to check, but large to store on-chain. 
Then, we generate a ZK proof for the said math proof 
as a much smaller cryptographic artifact that is more suitable for
being checked and stored on-chain. 
Both the math proof and the ZK proof are directly based on a mathematical model of
the program and the underlying language, known as their formal semantics. 

The key idea of Proof of Proof is to separate three underlying concerns: \textit{computation}, \textit{verification}, and \textit{cryptography}.
Firstly, recent developments in executable formal semantics and \K 
allow us to efficiently and completely automatically reduce computation to math proofs.  Proof of Proof only needs one language for encoding math proofs in order to 
support computations done with any programs in any programming languages (PLs) or virtual machines (VMs).
Secondly, the math proofs are checked, not trusted, with a disarmingly simple and small proof checker of only a few hundred lines of code.  
No (usually complex and error-prone) compilers, interpreters, or even formal verifiers
need to be trusted, either.
All become just instruments to assist the generation of math proofs.
The math proofs, and not the tools that generate them,
are the ultimate correctness arguments for the computations from which they were derived.
Finally, recent developments in cryptography and ZK (e.g., SNARK and STARK) allow us to implement the math proof checker 
as a cryptographic circuit, which effectively allows us to produce ZK proofs 
for the integrity of the math proofs,
and thus, (ZK) Proofs of (math) Proofs. 

\subsection{Pi Squared's Universality Stack}

Building on top of \K and Proof of Proof,
Pi Squared proposes the following universality tech stack that consists of
the following three components:
\begin{itemize}
    \item \textbf{Universal Settlement Layer (USL)}, a common layer for any applications and blockchains to submit, verify, settle, store, and use claims
    across platforms and ecosystems, compatible with various proof mechanisms and systems; 
    \item \textbf{Universal Language Machine (ULM)}, a truly universal execution layer
    that allows developers to write and deploy smart contracts in all programming languages, including Bring Your Own Language (BYOL), and enables interactions
    among the smart contracts;
    \item \textbf{Universal Consensus Protocol (UCP)}, a fast and novel 
    consensus protocol that enables nodes to agree on a set of independent values without imposing a global total order, 
    thereby facilitating massively parallel processing and validation.
\end{itemize}

\subsubsection{Universal Settlement Layer (USL)} 

Pi Squared's USL aims to address the issue of fragmentation and interoperability 
in Web3.
The current monolithic design of blockchains means that a blockchain handles
all the core tasks on the same layer, including
providing consensus and security, 
guaranteeing data availability, and executing transactions.
It makes communication \emph{within} the blockchain easy and convenient,
but communication \emph{across} various blockchains difficult and expensive. 
Each blockchain becomes an isolated information island. 

USL is a common layer that brings together various applications running on different blockchains and ecosystems,
using \emph{claims}. 
Claims are a core mathematical concept.
They refer to anything provable or verifiable. 
Transaction execution is captured by computation claims. 
State queries are captured by state query claims. 
Consensus validation is captured by consensus claims. 
Vetted information (e.g., knowledge or data) is captured by information claims. 
In short, all statements are formally represented as claims, and they are submitted to the USL
together with their corresponding proofs for verification, settlement, storage, and usage. 

Different types of claims have different types of proofs, and the USL is compatible
with any proof mechanisms. 
Computation claims can be verified against their math and/or ZK proofs, generated by any zkVMs at the choice of the users, or by re-executing the code 
using a trusted software configuration and hardware setup. 
State query claims can also be verified against their math proofs, ZK proofs, or by re-executing the corresponding pure/view functions.
Consensus claims can be verified by validating the blockchain's block headers. 
Information claims can be verified using digital signatures. 
The USL nodes are thus configurable and compatible with any of the above proof mechanisms. 

A remarkable and unique characteristic of the USL claims 
is that they are self-contained and can be verified independently. 
Neither the verification process nor the verification result of a USL claim depends on
any data, information, or state that is not given within the claim itself. 
Claims are the minimal self-contained and self-dependent verification unit. 
Therefore, once a claim is verified and settled by a USL node, it is added
to the ``valid claim set'' maintained by the USL node, which constitutes the node's runtime state. 
The valid claim set is a monotonic set that only increases as time passes by,
which gives birth to a faster consensus protocol which we term as the Universal Consensus Protocol (UCP). 

Any application running on any blockchain 
can query the USL about the claims 
about any other application on any other blockchain.
If a claim has been verified, settled, and stored on the USL, the USL returns a corresponding
\emph{membership proof}, which proves that the said claim indeed belongs to the valid claim set maintained by the USL node. 
No computation or complex consensus mechanism matters here, because the membership proof is simply a verifiable certificate for the simplest mathematical structure---a set---and the simplest mathematical relation---whether an object (claim) belongs to a set. 
Membership proofs are one of the simplest and most succinct verifiable certificates to verify and store on-chain. 

USL addresses the issue of Web3 fragmentation and interoperability by proposing a novel
topological structure among blockchain ecosystems.
Instead of building ad-hoc bridging-like solutions for any two blockchains and/or applications, 
the USL imposes a spoke–hub distribution paradigm that connects and interconnects various blockchains and ecosystems
via claims and membership proofs, in a uniform and universal way. 



\subsubsection{Universal Language Machine (ULM)} 

Pi Squared's ULM aims to leverage the universality of \K and Proof of Proof and bring this universality to Web3, to engage with a much larger community of Web2 developers who are not necessarily familiar with particular Web3 programming languages and technology stacks.

The ULM is an open-source execution layer that enables developers to create, deploy, and interact with smart contracts written in any programming language.
Unlike existing blockchain systems that require all contracts to be written in a single prescribed language, the ULM natively supports multiple languages.
Furthermore, the \ulm{} can be dynamically extended and allows adding new programming languages on-the-fly. 
This way, the ULM enables diverse language ecosystems to coexist and interoperate on a single platform.
This not only empowers developers to use the most suitable language for their projects; it also makes smart contract development more accessible to the millions of developers who are unfamiliar with existing Web3 languages.

Pi Squared is building the \ulm{} platform because we are convinced that its universal, formally grounded approach represents a significant advancement in the blockchain space that improves flexibility, developer experience, and security. At the same time, it paves the way for future innovation in decentralized applications, fostering a more universal approach to blockchain programming.

\subsubsection{Universal Consensus Protocol (UCP)} 

Pi Squared's UCP is a natural innovation in consensus mechanisms 
based on the unique characteristics of the USL, especially its self-contained
and independently-verifiable claims. 
Traditional counterparts in the current blockchain systems have focused 
on ordering transactions or blocks, 
introducing complexity and constraints that are often unnecessary for many decentralized applications.
The UCP, on the other hand, enables nodes to agree on a set of independent values (i.e., claims)
without imposing an order, thereby facilitating massively parallel processing and validation, which are critical for scalability and efficiency. 

Pi Squared's UCP decouples core consensus from application-specific requirements, particularly application-specific safety properties. These include the absence of forks in blockchain histories, prevention of double-spending in payment systems, ensuring only valid bids in auctions, or counting valid votes in voting systems. Such properties are the responsibility of the application to prove and are independent of the core consensus mechanism. This separation enables the design of a universally generic consensus protocol that serves as a unifying framework for diverse applications, including blockchain-based smart contracts, distributed databases, scientific computation validations, and multi-agent coordination systems. Furthermore, it facilitates the creation of scalable systems unbounded by any constraints imposed by the underlying protocol.

\subsubsection{Putting It All Together}

Pi Squared aims to empower Web3 developers to build interoperable and trust-minimized applications across 
all blockchain environments and ecosystems. 
By leveraging the \K framework,
Proof of Proof, and the Universality Stack,
dApp builders can unlock new possibilities for decentralized applications, move beyond the current silos of blockchain networks, and embrace an emerging new paradigm for trustless computing in crypto applications and beyond.
Through Verifiable Computing 2.0, Pi Squared is paving the way for a more unified, secure, and scalable future for Web3 infrastructure, and will continue playing
a pivotal role in shaping the next generation of decentralized computing.




\begin{center}
\noindent\fbox{\parbox{0.8\textwidth}{
Due to space limits, more technical details, experiments, analyses, and discussions 
are given in our technical whitepapers (see \Cref{sec:further}). 
}}
\end{center}

\section{\K Framework}
\label{sec:k}

\href{https://kframework.org}{\K framework} is a formal programming language semantics framework
that lies at the core infrastructure of Pi Squared.
It enables two things.
Firstly, \K allows to define, in a uniform and executable way,
the \emph{formal semantics} of any programming language.
Secondly, from the formal semantics of a language, \K automatically generates fast execution tools
for that language.

The formal semantics of a programming language is a mathematical definition of that language
and of all the behaviors of all the programs in that language.
Therefore, if one has the formal semantics of a programming language, then one has, in theory,
all the information needed to execute any program written in that language.
A formal semantics is similar to a language specification in that both describe
the expected behaviors of the programs.
The difference is that formal semantics is also mathematically rigorous and unambiguous,
and thus can be directly used for formal reasoning and proving.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{figs/k.png}
\caption{\K Framework}
\label{fig:K}
\end{figure}

Using their formal semantics, \K unifies programming languages.
As shown in \Cref{fig:K},
the center bubble
represents the formal semantics of an arbitrary programming language,
and the bubbles around represent the language tools that are automatically generated
directly from the formal semantics by \K.
This way, 
\K enables a \emph{separation of concerns} between
programming language design and programming language tool implementation.
Language designers can laser focus on designing and defining their languages (and tools) rigorously,
and let \K automatically generate all the tools needed to execute and reason about programs.

\subsection{\K Specifications}
\label{sec:kspec}

The primary input into the entire \K framework is a formal semantics of a programming language,
represented as a \K specification.
At the highest level, \K defines a programming language using three different pieces:
\begin{itemize}
\item \textbf{System primitives}: The base datatypes used during system operation, such as numbers, lists, maps, and so on.
\item \textbf{System configuration}: A nested tuple or record over the system primitives that gives a complete snapshot of the running system at any given runtime moment; can be seen as a semantic core dump.
\item \textbf{System behavior}: A set of rules that modularly specify all possible evolutions and behaviors of the system.
\end{itemize}
As a result, the \K specification of a programming language
is organized by a collection of \emph{declarations}
that correspond to the three pieces above:
\begin{itemize}
\item \emph{Syntax declarations} encode the system primitives.
\item \emph{Configuration declarations} encode the system configurations.
\item \emph{Context and rule declarations} encode the system behavior.
\end{itemize}

\K has been successfully applied to define the formal semantics of 
C~\cite{c-semantics}, 
Java~\cite{java-semantics}, 
JavaScript~\cite{kjs}, 
Python~\cite{python-semantics}, 
Rust~\cite{krust-shanghai,krust-singapore},
EVM (the bytecode language of Ethereum VM)~\cite{kevm}, 
WASM~\cite{kwasm}, 
x86-64~\cite{DPK+19}, 
and many others.

\subsection{\K Process}
\label{sec:kprocess}

Once we obtain the \K specification of the formal semantics of a programming language,
we pass it to \K as the primary input to generate all the language tools.
For efficiency, the \K spec is first desugared into an intermediate representation called Kore.
The Kore spec is used to do:
\begin{itemize}
\item Parsing and pretty-printing.
\item Concrete and symbolic program execution using the \K specification.
\item Symbolic reasoning, theorem proving and formal verification, i.e., proving claims about programs against the \K specification.
\end{itemize}
The above \K process is shown in \Cref{fig:kprocess}.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figs/kprocess.png}
\caption{\K Framework Process}
\label{fig:kprocess}
\end{figure}

\subsection{\K Backend}
\label{sec:kbackend}

LLVM-\K is a backend of \K that powers the \K execution process in \Cref{fig:kprocess},
specialized for concrete (non-symbolic) program execution.
It enables fast and correct-by-construction program execution for all languages, by
using their formal semantics.

As shown in \Cref{fig:kllvm},
the LLVM-\K backend generates fast, native interpreter binaries in LLVM IR for programming languages
from their formal semantics in \K.
The input to the LLVM-\K backend
is the Kore specification of a programming language, obtained by compiling the
\K specification of the language,
where Kore is the internal intermediate representation format of \K.
The output of the LLVM-\K backend is an efficient interpreter for the programming language
as an LLVM IR.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figs/kllvm.png}
\caption{LLVM-\K Architecture}
\label{fig:kllvm}
\end{figure}

\K is a rewrite-based system.
Formal semantics are given in terms of \emph{rewrite rules}, which specify how to go from
the current configuration to the next configuration.
This process is called \emph{rewriting}, and is driven by \emph{pattern matching}.
For any given configuration, a rewrite rule is selected that matches the said configuration.
During pattern matching,
the variables of the rewrite rules are given concrete values
according to the configuration that they are matched against.
This mapping from variables to concrete terms is called a \emph{substitution}.
After the pattern has been matched and we have a substitution,
we can rewrite the current configuration to the next one by
applying the substitution to the rewrite rule.

The LLVM-\K backend implements a high-performance pattern matching algorithm that is specialized to
handle large formal semantics of programming languages with
potentially thousands of rewrite rules to select from.
The core algorithm is based on a modified version of an
existing algorithm for code generation of efficient pattern matching, described in~\cite{Maranget2008}.
The algorithm represents the left-hand sides of the rewrite rules as matrices,
and processes these matrices into a decision tree.
Starting from the root of the tree, each node is a check on a specific position of the given term and the children of the node represent how to continue checking given the result of the parent’s check.
A leaf node corresponds to a specific rewrite rule that matches when the leaf node is reached through a series of checks on the given term.
The algorithm is designed to be customized with various heuristics in order to lead to generation of decision trees that minimize the number of checks needed to match a given term.

\subsection{\K Performance}

Semantics-based execution is fast. 
The interpreters that are automatically generated by \KL can reach comparable performance against
hand-written interpreters. 
Furthermore, semantics-based execution enables a number of optimization technologies
that are simply not possible in a traditional compiler-based approach. 

A typical example is \emph{compositional symbolic execution} (CSE). 
Given a formal semantics of a programming language $L$ and a program $P$,
the CSE automatically derives a new semantics $L[P]$, which is the partial evaluation 
of $P$ using the semantics of $L$. 
In other words, $L[P]$ is a new language and a new semantics that is specialized, and thus optimized, with respect to
the program $P$. 
All the basic blocks of $P$ that require multiple rewrite rules to execute using the semantics $L$
will be automatically summarized into their corresponding rewrite rules in $L[P]$, and thus each basic block is executed in one step, using the new CSE-ed version of the semantics. 

We have evaluated the performance of \KL on two benchmark set:
the blockchain tests in the Ethereum test suite~\cite{ethereum-tests}
and the execution of 1,000 swap operations on an ERC20 token~\cite{1kswapscode}. Our results are 
preliminary but positive.
We find that on EVM, \K without CSE is merely 1.35x slower than \code{geth}, 
the official implementation of EVM~\cite{geth} in Go and the most adopted Ethereum client.
Furthermore, if we enable the CSE, 
the language interpreters generated by \K outperform \code{geth} by 1.58x.


\section{Proof of Proof}
\label{sec:pop}

Proof of Proof is a universal verifiable computing framework for all programming languages.
Its universality comes from \K and formal semantics,
and the usage of mathematics and proofs
in specifying and reasoning about programs and languages.
In other words,
computation \emph{is} proof:
\begin{equation*}
\boxed{\text{Computation}} = \boxed{\text{Proof\vphantom{Cp}}}
\end{equation*}


\subsection{Main Workflow}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figs/pop.png}
\caption{Proof of Proof Workflow}
\label{fig:pop}
\end{figure}

\Cref{fig:pop} shows the entire Proof of Proof workflow. It has two phases.
In the first phase, we generate a mathematical proof that verifies that
a given execution trace of a program is indeed correct with respect to the formal semantics of the programming language.
Formally,
\begin{equation}
\Pi \colon \Gamma^L \vdash \varphi_P \qquad\text{where}
\label{eq:mathproof}
\end{equation}
\begin{itemize}
    \item $\Pi$ is the mathematical proof
    \item $\Gamma^L$ is the formal semantics of some programming language $L$
    \item $\varphi_P$ is the logical formula that specifies the correctness (w.r.t. $L$) of an execution trace
of a program $P$.
\end{itemize}
 
The symbol ``$\vdash$'' is called the entailment relation.
\Cref{eq:mathproof}
thus states that the mathematical proof $\Pi$ verifies the execution trace of program $P$
as specified by $\varphi_P$ with respect to the underlying formal semantics $\Gamma^L$.
The process of generating the mathematical proof $\Pi$
is called Math Proof Generation, and is depicted at the bottom left of \Cref{fig:pop}.

In the second phase of Proof of Proof, we generate a zero-knowledge proof (ZKP) that verifies the
(constructive) existence of a mathematical proof, for a given program execution claim.
Formally,
\begin{equation}
\pi \colon \text{ there exists $\Pi$ such that } \Pi \colon \Gamma^L \vdash \varphi_P
\label{eq:zkproof}
\end{equation}
In other words, we regard \Cref{eq:mathproof}
as a ternary relation among $\Pi$, $\Gamma^L$, and $\varphi_P$, and regard $\Pi$ is a private argument.
The zero-knowledge proof $\pi$ verifies the \emph{existence} of a mathematical proof for a given
execution trace of a given program, and thus forms an indirect certificate to computation.

Proof of Proof is thus an approach to verifiable computing
via two phases and two different types of proofs: mathematical proofs first, followed by zero-knowledge proofs.
In this order, not mixed.
Mathematical proofs are generated for the target execution traces based on formal semantics,
and zero-knowledge proofs are generated to show the existence of the mathematical proofs.
Hence, we name the approach ``Proof of Proof'':
\begin{equation*}
\boxed{\text{Proof of Proof}} = \boxed{\text{ZK Proof of Math Proof}}
\end{equation*}

\subsection{Math Proof Generation}

Math Proof Generation is the process of generating the mathematical proofs
for a given execution trace of a program using directly
the formal semantics of the underlying programming language.
The execution of the program is carried out by \K and the LLVM-\K backend,
as explained in \Cref{sec:k}.
Math Proof Generation consists of four main components:
\begin{enumerate}
\item  A universal logical foundation.
\item Proof hints.
\item Proof generation procedures.
\item Math proof checkers.
\end{enumerate}

The universal logical foundation that powers Proof of Proof is \emph{matching logic}
\cite{matchinglogichomepage}. 
All \K specifications correspond to logical theories of matching logic
and all \K tools, including the LLVM-\K backend,
are formally specified by matching logic formulas --- and this process is automatic.

Proof hints are the necessary information that \K generates on-the-fly
to facilitate the generation of the mathematical proofs,
including
the complete execution trace with all the intermediate configuration snapshots
as well as the information about how the rewrite rules have been matched and applied.
Proof hints are logs of the execution of the \K-generated interpreters.
Once generated, proof hints are passed into the proof generation procedures to generate the corresponding mathematical proofs.

Suppose the execution trace has the form $\varphi_1, \varphi_2,\dots,\varphi_n$.
Here, we write $\varphi_1,\varphi_2,\dots,\varphi_n$ to mean the intermediate configurations
that constitute the entire execution trace.
The corresponding mathematical proof
$\Pi \colon \Gamma^L \vdash \varphi_1 \To \varphi_n$ consists of four components:
\begin{enumerate}
\item The formalization of matching logic and its entailment relation ``$\vdash$''.
\item The formalization of the formal semantics $\Gamma^L$.
\item The proofs of all one-step executions, i.e.,
$\Gamma^L \vdash \varphi_i \To \varphi_{i+1}$ for all $i$.
\item The proof of the target trace
$\Pi \colon \Gamma^L \vdash \varphi_1 \To \varphi_n$.
\end{enumerate}
It should be noted that the mathematical proof as shown above has a linear structure
that enables proof checking in parallel.
Indeed, the formalization of matching logic and its entailment relation is
general, and is not specific to a programming language or a program,
so it can be proved once and for all.
The formalization of the formal semantics $\Gamma^L$ can be reused for all programs written
in the language $L$.

A math proof checker is a program that checks whether a mathematical proof
indeed verifies a mathematical claim.
As shown in \Cref{fig:pop}, we support two proof checkers for two proof formats.
The first is a math proof checker based on \href{https://metamath.org}{Metamath}, which has only 200 lines of code and thus forms a minimal trust base of Proof of Proof.
The second is a custom math proof checker based on our recent block model format, which is specialized
for the most efficient generation of ZK proofs.

\subsection{Zero-Knowledge Proof Generation}

Recall that zero-knowledge proof (ZKP) generation is the process of generating
a ZKP $\pi$ as shown below:
\begin{equation*}
\pi \colon \text{ there exists $\Pi$ such that } \Pi \colon \Gamma^L \vdash \varphi_P
\end{equation*}
In other words, we are generating ZKPs for the existence of a mathematical proof of a given, public
mathematical claim.

A generic ZK proof system designed to verify a particular computation
typically requires that the computation be specified via \textit{arithmetization}.
This reduces the computation into some ZK primitives, such as a system of algebraic equations or polynomials
over a finite field.
On the other hand, a zero-knowledge virtual machine (zkVM) verifies computations described by a program that runs on a virtual machine, and thus allows programs written in higher-level languages,
even programs not initially designed with verifiable computing in mind,
to be used in ZKP systems.

Pi Squared pursues both approaches at the same time and enables ZKP generation
via both existing zkVMs for best compatibility and via our own block model
for best arithmetization efficiency.
We discuss both.

\subsubsection{ZKP Generation via Existing zkVMs}

zkVMs are a type of software that supports producing ZKPs
of execution for some target language, for example,
RISC-V or the Ethereum VM instruction set.
By implementing the math proof checkers (see \Cref{fig:pop})
in a zkVM, we obtain an instance of Proof of Proof whose output verifiable certificates can be
directly produced and checked by the zkVM.

We have implemented
the same Metamath-based math proof checker
in seven different zkVMs: Cairo, Jolt, Lurk, Nexus, RISC Zero, SP1, and zkWASM.
Each consists of a guest program that runs on a specific virtual machine
and a host program, which is our interface to run the guest,
providing input for it and processing its output.

Among the seven zkVMs, five of them, namely Jolt, Nexus, RISC Zero, SP1 and zkWASM provides a Rust compiler.
For these Rust-based systems, we have developed and used a shared library.
Cairo and Lurk use domain-specific languages, namely the Cairo language and LISP.
We have implemented the same Metamath-based math proof checker in Cairo and Lurk,
but their code base was developed independently of the Rust code base and independent of each other.

Among the seven zkVMs, four of them have dedicated GPU support,
namely RISC Zero, zkWASM, SP1, and Cairo.
At the time of writing, January 2025, we were able to enable the GPU support on RISC Zero, SP1 and zkWASM.
GPU support on Cairo is a work in progress.

Our implementation and experiments are based on the following versions of the zkVMs:
\begin{itemize}
\item \textbf{Cairo} (the lambdaworks prover): Main branch, commit \href{https://github.com/lambdaclass/lambdaworks/commit/a591186e6c4dd53301b03b4ddd69369abe99f960}{a591186}
\item \textbf{Jolt}: Main branch, commit \href{https://github.com/a16z/jolt/commit/3b142426d9648299d9c6912e7e1b4698cf91491b}{3b14242}
\item \textbf{Lurk}: Main branch, commit \href{https://github.com/lurk-lab/lurk/commit/57c48b987a94ba1f9752408a0990882c9f4f506b}{57c48b9}
\item \textbf{Nexus}: Version \href{https://github.com/nexus-xyz/nexus-zkVM/releases/tag/v0.2.3}{0.2.3}
\item \textbf{RISC Zero}: Version 1.0.5
\item \textbf{SP1}: Dev branch, commit \href{https://github.com/succinctlabs/sp1/commit/2c7868364cb832531e8cafd258aa06fbab079459}{2c78683}
\item \textbf{zkWASM}: Main branch, commit \href{https://github.com/DelphinusLab/zkWasm/commit/f5acf8c58c32ac8c6426298be69958a6bea2b89a}{f5acf8c}
\end{itemize}

\subsubsection{ZKP Generation via Pi Squared's Block Model}

Generating ZKPs via zkVMs inevitably introduces extra complexity and overhead, due to encoding,
translation, and compilation.
A theoretically more efficient approach is to develop a ZK front-end that is specialized in math proof checking.
Pi Squared's block model is an approach for more efficiently ZK-proving math proofs.
The block model design is documented in
the ``\href{https://pi2.network/papers/proof-of-proof-whitepaper}{Proof of Proof white paper}'' while its related tool support
is a work in progress.


Pi Squared's block model is an intermediate computation model that is suitable for expressing
mathematical proof systems and can be implemented in an AIR/Plonkish arithmetization.
It also targets at connections with R1CS-native backends, and recursive SNARKs, and folding schemes.
The key observation of the block model
is that lookup arguments can more directly
support the task of checking that the hypotheses of math proof steps are conclusions of other steps, without building up a full RAM (or ROM) abstraction as for a zkVM.
Initial estimates based on theoretical and practical modeling of our math custom ZK circuit put it at about $1000\times$ faster than the off-the-shelf zkVM approach.



\section{Pi Squared's Universality Stack}

On top of \K and Proof of Proof,
Pi Squared proposes the universality tech stack that consists of 
Universal Settlement Layer (USL),
Universal Language Machine (ULM),
and Universal Consensus Protocol (UCP). 

\subsection{Universal Settlement Layer (USL)}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figs/usl.png}
\caption{Universal Settlement Layer (USL) Architecture}
\label{fig:usl}
\end{figure}

Pi Squared's USL is a distributed service that allows users to submit, verify, store, settle, and use claims,
as shown in \Cref{fig:usl}.
The central component of the USL is that of \emph{claims}. 
Claims can be anything mathematically provable and can be proved by any type of proof.
Users submit a claim and 
its corresponding proof to the USL, and the nodes of the USL validate the claim by checking its proof.
The USL is compatible with any proof mechanism. 
It allows validation-by-re-execution, which is the canonical computation validation approach in most of the state-of-the-art layer-1 blockchains. 
It allows validation-by-proof-certificates, where the certificates
can be the math/ZK proofs generated by Proof of Proof or any zkVMs. 
This way, the USL enables verifiable computing, 
open or secure, for the whole Web3 world through a versatile set of proofs.

At runtime, a node in the USL network maintains a set of claims that have been validated and settled. 
Because claims are self-contained statements that can be validated independently of each other, 
the USL node only needs to maintain all the validated claims as a set and not as an ordered sequence or list. 
There are two important characteristics of the claim sets within the USL nodes:
\begin{itemize}
    \item \textbf{Atomicity}. Claims are the smallest verifiable atom in the USL. 
     Each claim is self-contained and includes all the information for it to be 
     verified independently from the other claims. 
    \item \textbf{Timelessness}. Claims, once verified, continue staying valid regardless of time.  
     Timelessness is a natural corollary of atomicity. A time-sensitive or state-sensitive claim can be turned into
     a timeless/stateless claim by incorporating the time and/or the state as an argument of the claim. 
    \item \textbf{Monotonicity}. The set of claims maintained by a USL node only increases, and never decreases, as time passes. Monotonicity is a natural corollary of timelessness. Since valid claims continue staying valid, the USL node does not need to bother re-verifying claims and removing those that are no longer valid. 
\end{itemize}
This way, the USL opens the door to a more generalized and efficient Universal Consensus protocol
because unlike traditional blockchains, the USL network does not enforce the total ordering of its claims
(the USL ``transactions'').

Any applications or users can submit claims to the USL for verification and settlement. 
Depending on their use cases and the needs, these claims can have various types,
such as transaction claims (i.e., computation claims), 
state query claims, consensus claims, and/or vetted information claims. 
Every claim must be associated with a corresponding proof, and thus forms
a pair $\langle c, \pi \rangle$, where $c$ is the mathematical representation of the claim
and $\pi$ is a proof that can be verified by the USL node. 

\subsection{Universal Language Machine (ULM)}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figs/ulm.png}
\caption{Universal Language Machine (ULM) Architecture}
\label{fig:ulm}
\end{figure}

The Universal Language Machine (ULM) is an open-source execution layer
platform that enables developers to create, deploy, and interact with smart contracts written in any programming language.
Unlike existing blockchain systems that require all contracts to be written in a single prescribed language, the ULM natively supports multiple languages.
This way,
the ULM enables diverse language ecosystems to coexist and interoperate on a single platform,
which not only empowers developers to use the most suitable language for their projects
but also makes smart contract development accessible to a much larger developer base.

Pi Squared's ULM is based on \K and formal semantics and thus adopts a mathematically grounded approach to
language support.
It uses \K and the formal semantics of programming languages to execute smart contracts written
in any programming language in a correct-by-construction manner.
The ULM is a significant advancement in flexibility, developer experience, and security,
and it paves the way for future innovation in decentralized applications,
fostering a more universal approach to Web3 development.


The overview architecture of the ULM is depicted in \Cref{fig:ulm}.
The core component is a semantics-based execution layer, powered by the \K framework and the formal semantics.
This semantics-based execution layer is loosely connected to and
actively interacting with an external consensus layer.
The modular design of the ULM enables it to interact with a variety of consensus algorithms and schemes, including BFT protocols.
In the future, we expect and look forward to making the ULM compatible with more consensus protocols.
At present, we are collaborating with the \href{https://www.commonprefix.com/}{Common Prefix} team
to connect the ULM to a POD-like weak/generalized consensus protocol for faster finality of the ULM transactions.

The ULM allows smart contracts written in different programming languages to coexist.
When a contract is deployed or called, ULM determines the correct semantics module 
to execute the contract code.
All smart contracts are able to modify the same blockchain state thanks to
a single universal API that provides access control and allows each semantics to update the storage of its own namespace only.
A language semantics can only modify the contract storage under its own namespace.
This namespace access control policy prevents malicious semantics from harming the storage of contracts written in other languages.

The LM is a \emph{truly universal} framework
because all smart contracts written in any programming languages
are directly and natively executed using the formal semantics, without compilation, thus avoiding compiler bugs.
Furthermore, the ULM architecture, as shown in \Cref{fig:ulm}, is extensible and enables dynamic addition of new programming languages.
Smart contracts written in various programming languages are connected to the \K framework
as modules.
Users are able to plug and play their programming languages, even their own customized languages,
as long as the formal semantics have been defined in \K.
This way, the ULM fosters continuous innovation in smart contract development.





\subsection{Universal Consensus Protocol (UCP)}

In the ULM and the USL, claims are the core of validation and consensus.
A claim can represent various types of assertions and is independently evaluated for correctness without relying on the order of processing.
This contrasts with traditional blockchain consensus, which requires agreement on a globally ordered sequence of transactions to prevent conflicts and maintain consistency.

Pi Squared's UCP is a novel distributed consensus algorithm specifically designed to operate on claims.
The UCP enables achieving agreement on the validity of claims in a permissionless, decentralized network.
At its core is the concept of set consensus, where the focus shifts from ordering values to achieving agreement on a set of independent claims.
Instead of requiring a strict sequence, users propose claims in parallel,
and the goal of the network is to agree on the valid subset of those claims by verifying their proofs.
This enables concurrent validation, reducing the complexity and overhead associated with traditional blockchain systems.

Clients are nodes responsible for: (1) providing claims that require validation and (2) maintaining an up-to-date view of the network’s state. Validators, on the other hand, are nodes tasked with individually verifying these claims to ensure that only claims that are verified as correct (i.e., their provided proofs check) are maintained by the protocol.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figs/connection_graph.png}
\caption{Universal Consensus Protocol (UCP) Connection Topology}
\label{fig:uc}
\end{figure}

Inspired by POD~\cite{AlposADZ:2025}, the UCP uses a broadcast model that is based on a communication topology of a complete bipartite graph of clients and validators, as illustrated in Figure~\ref{fig:uc}. Importantly, validators do not need to communicate with one another as they maintain local logs of verified claims. Clients maintain streaming and stateful connections to all validators.
Validators are identified by public keys registered in a public key infrastructure (PKI). They sign all outgoing messages with digital signatures, providing cryptographic assurance of message authenticity and integrity since signatures cannot be forged.

The UCP is designed to tolerate Byzantine nodes that act arbitrarily or deviate from the protocol rules. As in POD~\cite{AlposADZ:2025}, we assume a limit on the resilience threshold $\beta$, which is the number of malicious validators (typically $(n-1)/3$ where $n$ is the total number of validators). There is no inherent assumption about the honesty of clients.


The UCP has the following key advantages:
\begin{itemize}
\item \textbf{Order independence}: Set consensus does not enforce an ordering of values, not even partial, allowing for parallel validation and processing.
\item \textbf{Scalability}: By eliminating the need for ordering, set consensus supports higher throughput and lower latency, unlike blockchain systems that sacrifice scalability for order and consistency.
\item \textbf{Separation of concerns}: The validity of claims is evaluated independently from application-specific safety properties, such as transaction order or state transition requirements. This flexibility allows the consensus protocol to support diverse use cases, from decentralized exchanges requiring strict ordering to voting systems where order does not matter.
\end{itemize}

The security of the UCP is established through key theorems. The \textbf{correctness} theorem ensures that invalid claims are never finalized in the view of an honest client, though they may temporarily appear as pending. The \textbf{view consistency} theorem guarantees that during partial synchrony with a network delay $\delta$, if a claim is observed as finalized by one honest client, it will be observed as finalized by all honest clients within $u = 2\delta$, ensuring consistent views. Finally, the \textbf{finalization} theorem ensures that valid claims are finalized within $w = 2\delta + \tau$ during partial synchrony, where $\tau$ is an upper bound on claim verification time, ensuring the progression of finalized claims in honest client views.

\section{Conclusion and Further Readings}
\label{sec:further}

We have introduced Pi Squared and its three major technological innovations:
the \K framework, Proof of Proof, and the 3-component Universality Stack 
that consits of
the Universal Settlement Layer (USL),
the Universal Language Machine (ULM),
and the Universal Consensus Protocol (UCP). 
By leveraging these core technologies, Pi Squared will empower Web3 developers to build interoperable and trust-minimized applications across multiple blockchain environments
and paving the way for a more unified, secure, and scalable future for Web3 infrastructure.

We have outlined the major technology building blocks in this umbrella white paper.
Deeper technical white papers, as well as several research and peer-reviewed papers, are available on 
\href{https://pi2.network/papers}{\texttt{pi2.network}}, in particular:
\begin{itemize}
\item \href{https://pi2.network/papers/llvm-k-whitepaper}{K Framework}
\item \href{https://pi2.network/papers/proof-of-proof-whitepaper}{Proof of Proof}
\item \href{https://pi2.network/papers/universality-whitepaper}{Pi Squared's Universality Stack (USL + ULM + UCP)}
\end{itemize}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
